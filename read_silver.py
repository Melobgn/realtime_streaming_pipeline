"""
Delta Lake Reader â€“ Silver Layer

This script reads the Delta Lake Silver table generated by the
Spark streaming job and displays the most recent records.
"""

from pyspark.sql import SparkSession

SILVER_PATH = "lake/silver/sensor_data"
DELTA_PACKAGE = "io.delta:delta-spark_2.13:4.0.0"


def build_spark() -> SparkSession:
    """
    Build a SparkSession with Delta Lake support.
    """
    return (
        SparkSession.builder
        .appName("Read-Delta-Silver")
        .master("local[*]")
        .config("spark.sql.shuffle.partitions", "2")
        .config("spark.jars.packages", DELTA_PACKAGE)
        .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension")
        .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")
        .getOrCreate()
    )


def main() -> None:
    """
    Read and display the Delta Silver table.
    """
    spark = build_spark()
    spark.sparkContext.setLogLevel("WARN")

    df = spark.read.format("delta").load(SILVER_PATH)
    df.orderBy(df.ingest_time.desc()).show(20, truncate=False)


if __name__ == "__main__":
    main()
